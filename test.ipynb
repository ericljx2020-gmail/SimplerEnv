{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:25:48.987] [svulkan2] [error] GLFW error: X11: The DISPLAY environment variable is missing\n",
      "[2025-04-29 04:25:48.987] [svulkan2] [warning] Continue without GLFW.\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset info {'scene_name': 'google_pick_coke_can_1_v4', 'scene_offset': None, 'scene_pose': None, 'scene_table_height': 0.87, 'urdf_version': 'recolor_tabletop_visual_matching_1', 'rgb_overlay_path': '/data/jul108/SimplerEnv/ManiSkill2_real2sim/data/real_inpainting/google_coke_can_real_eval_1.png', 'rgb_overlay_cameras': ['overhead_camera'], 'rgb_overlay_mode': 'background', 'disable_bad_material': False, 'model_id': 'opened_coke_can', 'model_scale': 1.0, 'distractor_model_ids': None, 'distractor_model_scales': None, 'obj_init_pose_wrt_robot_base': Pose([0.587925, -0.0238302, 0.840576], [0.707052, -0.0081018, -0.01162, -0.70702]), 'orientation': 'laid_vertically'}\n",
      "Instruction pick coke can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation.image.top': {'shape': [3, 224, 224], 'type': 'VISUAL'}, 'observation.state': {'shape': [7], 'type': 'STATE'}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/data/jul108/SimplerEnv/test.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m policy\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m load_pi0_config_from_json(\u001b[39m\"\u001b[39m\u001b[39m/data/jul108/lerobot/config.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(policy\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39minput_features) \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m action \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mselect_action(batch) \u001b[39m# replace this with your policy inference\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m obs, reward, done, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action) \u001b[39m# for long horizon tasks, you can call env.advance_to_next_subtask() to advance to the next subtask; the environment might also autoadvance if env._elapsed_steps is larger than a threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m new_instruction \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mget_language_instruction()\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/common/policies/pi0/modeling_pi0.py:281\u001b[0m, in \u001b[0;36mPI0Policy.select_action\u001b[0;34m(self, batch, noise)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m# Action queue logic for n_action_steps > 1. When the action_queue is depleted, populate it by\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m# querying the policy.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_queue) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     images, img_masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_images(batch)\n\u001b[1;32m    282\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_state(batch)\n\u001b[1;32m    283\u001b[0m     lang_tokens, lang_masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_language(batch)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/common/policies/pi0/modeling_pi0.py:345\u001b[0m, in \u001b[0;36mPI0Policy.prepare_images\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    342\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[1;32m    343\u001b[0m img_masks \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 345\u001b[0m present_img_keys \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mimage_features \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m    346\u001b[0m missing_img_keys \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mimage_features \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(present_img_keys) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/configs/policies.py:121\u001b[0m, in \u001b[0;36mPreTrainedConfig.image_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimage_features\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, PolicyFeature]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: ft \u001b[39mfor\u001b[39;00m key, ft \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_features\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m ft\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m FeatureType\u001b[39m.\u001b[39mVISUAL}\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/configs/policies.py:121\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimage_features\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, PolicyFeature]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: ft \u001b[39mfor\u001b[39;00m key, ft \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_features\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m ft\u001b[39m.\u001b[39;49mtype \u001b[39mis\u001b[39;00m FeatureType\u001b[39m.\u001b[39mVISUAL}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import matplotlib.pyplot as plt\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "\n",
    "\n",
    "env = simpler_env.make('google_robot_pick_coke_can')\n",
    "obs, reset_info = env.reset()\n",
    "instruction = env.get_language_instruction()\n",
    "print(\"Reset info\", reset_info)\n",
    "print(\"Instruction\", instruction)\n",
    "\n",
    "done, truncated = False, False\n",
    "while not (done or truncated):\n",
    "   # action[:3]: delta xyz; action[3:6]: delta rotation in axis-angle representation;\n",
    "   # action[6:7]: gripper (the meaning of open / close depends on robot URDF)\n",
    "   image = get_image_from_maniskill2_obs_dict(env, obs)\n",
    "   \n",
    "   # # Display the image\n",
    "   # plt.figure(figsize=(10,10))\n",
    "   # plt.imshow(image)\n",
    "   # plt.axis('off')\n",
    "   # plt.show()\n",
    "   batch = {\n",
    "      \"image\": image,\n",
    "      \"task\": [instruction],\n",
    "   }\n",
    "   policy = PI0Policy.from_pretrained(\"lerobot/pi0\")\n",
    "   action = policy.select_action(batch) # replace this with your policy inference\n",
    "   obs, reward, done, truncated, info = env.step(action) # for long horizon tasks, you can call env.advance_to_next_subtask() to advance to the next subtask; the environment might also autoadvance if env._elapsed_steps is larger than a threshold\n",
    "   new_instruction = env.get_language_instruction()\n",
    "   if new_instruction != instruction:\n",
    "      # for long horizon tasks, we get a new instruction when robot proceeds to the next subtask\n",
    "      instruction = new_instruction\n",
    "      print(\"New Instruction\", instruction)\n",
    "\n",
    "episode_stats = info.get('episode_stats', {})\n",
    "print(\"Episode stats\", episode_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jul108/.cache/hub/models--lerobot--pi0/snapshots/8f50aacbe079a026391616cf22453de528f2a873/config.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "print(hf_hub_download(\"lerobot/pi0\", \"config.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:48:00.765] [svulkan2] [error] GLFW error: X11: The DISPLAY environment variable is missing\n",
      "[2025-04-29 04:48:00.765] [svulkan2] [warning] Continue without GLFW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset info {'scene_name': 'google_pick_coke_can_1_v4', 'scene_offset': None, 'scene_pose': None, 'scene_table_height': 0.87, 'urdf_version': 'recolor_tabletop_visual_matching_1', 'rgb_overlay_path': '/data/jul108/SimplerEnv/ManiSkill2_real2sim/data/real_inpainting/google_coke_can_real_eval_1.png', 'rgb_overlay_cameras': ['overhead_camera'], 'rgb_overlay_mode': 'background', 'disable_bad_material': False, 'model_id': 'opened_coke_can', 'model_scale': 1.0, 'distractor_model_ids': None, 'distractor_model_scales': None, 'obj_init_pose_wrt_robot_base': Pose([0.587925, -0.0238302, 0.840576], [0.707052, -0.0081018, -0.01162, -0.70702]), 'orientation': 'laid_vertically'}\n",
      "Instruction pick coke can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import matplotlib.pyplot as plt\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "\n",
    "\n",
    "env = simpler_env.make('google_robot_pick_coke_can')\n",
    "obs, reset_info = env.reset()\n",
    "instruction = env.get_language_instruction()\n",
    "print(\"Reset info\", reset_info)\n",
    "print(\"Instruction\", instruction)\n",
    "\n",
    "image = get_image_from_maniskill2_obs_dict(env, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:56:28.364] [svulkan2] [warning] A second renderer will share the same internal context with the first one. Arguments passed to constructor will be ignored.\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: pick coke can\n"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import torch, numpy as np\n",
    "from PIL import Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# ---- 1. 加载 π0（自定义 config，避免 DecodingError） ----\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "from lerobot.configs.types import FeatureType, NormalizationMode, PolicyFeature\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "INPUT = {\n",
    "    \"observation.image.top\": PolicyFeature(type=FeatureType.VISUAL, shape=(3, 224, 224)),\n",
    "    \"observation.state\":     PolicyFeature(type=FeatureType.STATE,  shape=(7,)),\n",
    "}\n",
    "OUTPUT = {\"action\": PolicyFeature(type=FeatureType.ACTION, shape=(7,))}\n",
    "\n",
    "cfg = PI0Config(\n",
    "    input_features=INPUT,\n",
    "    output_features=OUTPUT,\n",
    "    normalization_mapping={\"VISUAL\": NormalizationMode.IDENTITY,\n",
    "                           \"STATE\":  NormalizationMode.IDENTITY,\n",
    "                           \"ACTION\": NormalizationMode.IDENTITY},\n",
    "    device=device,\n",
    ")\n",
    "dummy_stats = {k: {\"mean\": torch.zeros(v.shape), \"std\": torch.ones(v.shape)} for k, v in INPUT.items()}\n",
    "dummy_stats[\"action\"] = {\"mean\": torch.zeros(7), \"std\": torch.ones(7)}\n",
    "\n",
    "policy = PI0Policy.from_pretrained(\n",
    "    \"lerobot/pi0\",          # 会自动下载权重到 ~/.cache/huggingface/hub\n",
    "    config=cfg,\n",
    "    dataset_stats=dummy_stats,\n",
    "    strict=False,           # 忽略缺失 buffer\n",
    ").eval()\n",
    "\n",
    "# ---- 2. 创建 SIMPLER 环境 ----\n",
    "env = simpler_env.make(\"google_robot_pick_coke_can\")\n",
    "obs, reset_info = env.reset()\n",
    "inst = env.get_language_instruction()\n",
    "print(\"Instruction:\", inst)\n",
    "\n",
    "# ---- 3. 主循环 ----\n",
    "done = truncated = False\n",
    "while not (done or truncated):\n",
    "    # 3.1 取图像并缩放到 (3,224,224)\n",
    "    img_np = get_image_from_maniskill2_obs_dict(env, obs)     # (H,W,3) RGB\n",
    "    img_pil = Image.fromarray(img_np).resize((224, 224))\n",
    "    img = torch.as_tensor(np.array(img_pil)).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    # 3.2 取 7 维关节角（谷歌臂为 7 DoF；若找不到就用零向量）\n",
    "    state = torch.as_tensor(obs.get(\"agent\", {}).get(\"qpos\", np.zeros(7)))[:7].float()\n",
    "\n",
    "    # 3.3 封装 batch 并推断\n",
    "    batch = {\n",
    "        \"observation.image.top\": img.unsqueeze(0).to(device),\n",
    "        \"observation.state\":     state.unsqueeze(0).to(device),\n",
    "        \"task\": [inst],          # π0 需要文本指令\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        act = policy.select_action(batch).cpu().numpy()       # (7,)\n",
    "\n",
    "    break\n",
    "#     obs, reward, done, truncated, info = env.step(act)\n",
    "#     new_inst = env.get_language_instruction()\n",
    "#     if new_inst != inst:\n",
    "#         inst = new_inst\n",
    "#         print(\"New instruction →\", inst)\n",
    "\n",
    "# print(\"Episode stats:\", info.get(\"episode_stats\", {}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07079999,  0.26439357,  0.2961598 ,  1.3624268 , -0.17620404,\n",
       "         0.07293497, -0.05996808]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory /mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot is neither a `Dataset` directory nor a `DatasetDict` directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/jul108/SimplerEnv/test.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Approach 1: If the dataset was downloaded by Hugging Face and cached\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# local_path = \"/mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# ds = load_dataset(\"IPEC-COMMUNITY/bridge_orig_lerobot\", split=\"train\", data_dir=local_path, local_files_only=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Approach 2: If the dataset was saved using save_to_disk\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ds \u001b[39m=\u001b[39m load_from_disk(local_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Continue with your existing code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(ds\u001b[39m.\u001b[39mcolumn_names)\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/datasets/load.py:2148\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[39mreturn\u001b[39;00m DatasetDict\u001b[39m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory, storage_options\u001b[39m=\u001b[39mstorage_options)\n\u001b[1;32m   2147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   2149\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDirectory \u001b[39m\u001b[39m{\u001b[39;00mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2150\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory /mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot is neither a `Dataset` directory nor a `DatasetDict` directory."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np\n",
    "\n",
    "# Approach 1: If the dataset was downloaded by Hugging Face and cached\n",
    "# local_path = \"/mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot\"\n",
    "# ds = load_dataset(\"IPEC-COMMUNITY/bridge_orig_lerobot\", split=\"train\", data_dir=local_path, local_files_only=True)\n",
    "\n",
    "# Approach 2: If the dataset was saved using save_to_disk\n",
    "ds = load_from_disk(local_path)\n",
    "\n",
    "# Continue with your existing code\n",
    "print(ds.column_names)\n",
    "\n",
    "obs_array = np.stack(ds[\"obs\"])\n",
    "action_array = np.stack(ds[\"action\"])\n",
    "\n",
    "obs_mean = obs_array.mean(axis=0)\n",
    "obs_std = obs_array.std(axis=0)\n",
    "action_mean = action_array.mean(axis=0)\n",
    "action_std = action_array.std(axis=0)\n",
    "\n",
    "dataset_stats = {\n",
    "    \"obs_mean\": obs_mean.tolist(),\n",
    "    \"obs_std\": obs_std.tolist(),\n",
    "    \"action_mean\": action_mean.tolist(),\n",
    "    \"action_std\": action_std.tolist()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"config_with_stats.json\", \"w\") as f:\n",
    "    json.dump({\"dataset_stats\": dataset_stats}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-03 20:16:41.417579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-03 20:16:41.417642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-03 20:16:41.418637: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-03 20:16:41.425351: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-03 20:16:42.352172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json not found in /mnt/pentagon/rutu/lerobot/outputs/train/2025-04-29/11-48-55_pi0/checkpoints/030000\n"
     ]
    },
    {
     "ename": "ParsingError",
     "evalue": "Expected a dict with a 'type' key for <class 'lerobot.configs.policies.PreTrainedConfig'>, got {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParsingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/jul108/SimplerEnv/test.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/mnt/pentagon/rutu/lerobot/outputs/train/2025-04-29/11-48-55_pi0/checkpoints/last\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load the finetuned model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m policy \u001b[39m=\u001b[39m PI0Policy\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     model_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m  \u001b[39m# In case of any minor architecture differences\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Move to appropriate device if needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m policy \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/common/policies/pretrained.py:97\u001b[0m, in \u001b[0;36mPreTrainedPolicy.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, config, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, strict, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mThe policy is set in evaluation mode by default using `policy.eval()` (dropout modules are\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mdeactivated). To train it, you should first set it back in training mode with `policy.train()`.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     config \u001b[39m=\u001b[39m PreTrainedConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     98\u001b[0m         pretrained_name_or_path\u001b[39m=\u001b[39;49mpretrained_name_or_path,\n\u001b[1;32m     99\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    100\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    101\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    102\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    103\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    104\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    105\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    106\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(pretrained_name_or_path)\n\u001b[1;32m    109\u001b[0m instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/configs/policies.py:176\u001b[0m, in \u001b[0;36mPreTrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **policy_kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m# HACK: this is very ugly, ideally we'd like to be able to do that natively with draccus\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# something like --policy.path (in addition to --policy.type)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m cli_overrides \u001b[39m=\u001b[39m policy_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcli_overrides\u001b[39m\u001b[39m\"\u001b[39m, [])\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m draccus\u001b[39m.\u001b[39;49mparse(\u001b[39mcls\u001b[39;49m, config_file, args\u001b[39m=\u001b[39;49mcli_overrides)\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/argparsing.py:211\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(config_class, config_path, args, prog, exit_on_error, preferred_help)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39mParses the command line arguments and returns an instance of the config class.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m    preferred_help: Preferred location to parse help text for fields (< \"inline\" | \"above\" | \"below\" >)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m parser \u001b[39m=\u001b[39m ArgumentParser(\n\u001b[1;32m    205\u001b[0m     config_class\u001b[39m=\u001b[39mconfig_class,\n\u001b[1;32m    206\u001b[0m     config_path\u001b[39m=\u001b[39mconfig_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     preferred_help\u001b[39m=\u001b[39mpreferred_help,\n\u001b[1;32m    210\u001b[0m )\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mparse_args(args)\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/argparsing.py:102\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 102\u001b[0m     args, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace, is_parse_args\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/argparsing.py:136\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace, is_parse_args)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[39mraise\u001b[39;00m DraccusException(msg)\n\u001b[0;32m--> 136\u001b[0m parsed_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocessing(parsed_args)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m parsed_t, unparsed_args\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/argparsing.py:180\u001b[0m, in \u001b[0;36mArgumentParser._postprocessing\u001b[0;34m(self, parsed_args)\u001b[0m\n\u001b[1;32m    178\u001b[0m deflat_d \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdeflatten(parsed_arg_values, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m deflat_d \u001b[39m=\u001b[39m mergedeep\u001b[39m.\u001b[39mmerge(file_args, deflat_d)\n\u001b[0;32m--> 180\u001b[0m cfg \u001b[39m=\u001b[39m decoding\u001b[39m.\u001b[39;49mdecode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class, deflat_d)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m cfg\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/parsers/registry_utils.py:78\u001b[0m, in \u001b[0;36mwithregistry.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m     77\u001b[0m     \u001b[39m# Unlike singledispatch we do not directly override the base call\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m base_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/parsers/decoding.py:48\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(cls, raw_value)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m@withregistry\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdecode\u001b[39m(\u001b[39mcls\u001b[39m: Type[T], raw_value: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     47\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m canonicalize_union(\u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m get_decoding_fn(\u001b[39mcls\u001b[39;49m)(raw_value, ())\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/draccus/parsers/decoding.py:185\u001b[0m, in \u001b[0;36mdecode_choice_class\u001b[0;34m(cls, raw_value, path)\u001b[0m\n\u001b[1;32m    183\u001b[0m     default \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdefault_choice_name()\n\u001b[1;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         \u001b[39mraise\u001b[39;00m ParsingError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a dict with a \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mCHOICE_TYPE_KEY\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m key for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mraw_value\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m     choice_type \u001b[39m=\u001b[39m default\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mParsingError\u001b[0m: Expected a dict with a 'type' key for <class 'lerobot.configs.policies.PreTrainedConfig'>, got {}"
     ]
    }
   ],
   "source": [
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "\n",
    "# Path to your model checkpoint\n",
    "model_path = \"/mnt/pentagon/rutu/lerobot/outputs/train/2025-04-29/11-48-55_pi0/checkpoints/last\"\n",
    "\n",
    "# Load the finetuned model\n",
    "policy = PI0Policy.from_pretrained(\n",
    "    model_path,\n",
    "    strict=False  # In case of any minor architecture differences\n",
    ")\n",
    "\n",
    "# Move to appropriate device if needed\n",
    "policy = policy.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "policy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
