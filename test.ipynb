{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:25:48.987] [svulkan2] [error] GLFW error: X11: The DISPLAY environment variable is missing\n",
      "[2025-04-29 04:25:48.987] [svulkan2] [warning] Continue without GLFW.\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset info {'scene_name': 'google_pick_coke_can_1_v4', 'scene_offset': None, 'scene_pose': None, 'scene_table_height': 0.87, 'urdf_version': 'recolor_tabletop_visual_matching_1', 'rgb_overlay_path': '/data/jul108/SimplerEnv/ManiSkill2_real2sim/data/real_inpainting/google_coke_can_real_eval_1.png', 'rgb_overlay_cameras': ['overhead_camera'], 'rgb_overlay_mode': 'background', 'disable_bad_material': False, 'model_id': 'opened_coke_can', 'model_scale': 1.0, 'distractor_model_ids': None, 'distractor_model_scales': None, 'obj_init_pose_wrt_robot_base': Pose([0.587925, -0.0238302, 0.840576], [0.707052, -0.0081018, -0.01162, -0.70702]), 'orientation': 'laid_vertically'}\n",
      "Instruction pick coke can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation.image.top': {'shape': [3, 224, 224], 'type': 'VISUAL'}, 'observation.state': {'shape': [7], 'type': 'STATE'}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/data/jul108/SimplerEnv/test.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m policy\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m load_pi0_config_from_json(\u001b[39m\"\u001b[39m\u001b[39m/data/jul108/lerobot/config.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(policy\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39minput_features) \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m action \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mselect_action(batch) \u001b[39m# replace this with your policy inference\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m obs, reward, done, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action) \u001b[39m# for long horizon tasks, you can call env.advance_to_next_subtask() to advance to the next subtask; the environment might also autoadvance if env._elapsed_steps is larger than a threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m new_instruction \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mget_language_instruction()\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/common/policies/pi0/modeling_pi0.py:281\u001b[0m, in \u001b[0;36mPI0Policy.select_action\u001b[0;34m(self, batch, noise)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m# Action queue logic for n_action_steps > 1. When the action_queue is depleted, populate it by\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m# querying the policy.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_queue) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     images, img_masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_images(batch)\n\u001b[1;32m    282\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_state(batch)\n\u001b[1;32m    283\u001b[0m     lang_tokens, lang_masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_language(batch)\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/common/policies/pi0/modeling_pi0.py:345\u001b[0m, in \u001b[0;36mPI0Policy.prepare_images\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    342\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[1;32m    343\u001b[0m img_masks \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 345\u001b[0m present_img_keys \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mimage_features \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m    346\u001b[0m missing_img_keys \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mimage_features \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(present_img_keys) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/configs/policies.py:121\u001b[0m, in \u001b[0;36mPreTrainedConfig.image_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimage_features\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, PolicyFeature]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: ft \u001b[39mfor\u001b[39;00m key, ft \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_features\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m ft\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m FeatureType\u001b[39m.\u001b[39mVISUAL}\n",
      "File \u001b[0;32m/data/jul108/lerobot/lerobot/configs/policies.py:121\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimage_features\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, PolicyFeature]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: ft \u001b[39mfor\u001b[39;00m key, ft \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_features\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m ft\u001b[39m.\u001b[39;49mtype \u001b[39mis\u001b[39;00m FeatureType\u001b[39m.\u001b[39mVISUAL}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import matplotlib.pyplot as plt\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "\n",
    "\n",
    "env = simpler_env.make('google_robot_pick_coke_can')\n",
    "obs, reset_info = env.reset()\n",
    "instruction = env.get_language_instruction()\n",
    "print(\"Reset info\", reset_info)\n",
    "print(\"Instruction\", instruction)\n",
    "\n",
    "done, truncated = False, False\n",
    "while not (done or truncated):\n",
    "   # action[:3]: delta xyz; action[3:6]: delta rotation in axis-angle representation;\n",
    "   # action[6:7]: gripper (the meaning of open / close depends on robot URDF)\n",
    "   image = get_image_from_maniskill2_obs_dict(env, obs)\n",
    "   \n",
    "   # # Display the image\n",
    "   # plt.figure(figsize=(10,10))\n",
    "   # plt.imshow(image)\n",
    "   # plt.axis('off')\n",
    "   # plt.show()\n",
    "   batch = {\n",
    "      \"image\": image,\n",
    "      \"task\": [instruction],\n",
    "   }\n",
    "   policy = PI0Policy.from_pretrained(\"lerobot/pi0\")\n",
    "   action = policy.select_action(batch) # replace this with your policy inference\n",
    "   obs, reward, done, truncated, info = env.step(action) # for long horizon tasks, you can call env.advance_to_next_subtask() to advance to the next subtask; the environment might also autoadvance if env._elapsed_steps is larger than a threshold\n",
    "   new_instruction = env.get_language_instruction()\n",
    "   if new_instruction != instruction:\n",
    "      # for long horizon tasks, we get a new instruction when robot proceeds to the next subtask\n",
    "      instruction = new_instruction\n",
    "      print(\"New Instruction\", instruction)\n",
    "\n",
    "episode_stats = info.get('episode_stats', {})\n",
    "print(\"Episode stats\", episode_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jul108/.cache/hub/models--lerobot--pi0/snapshots/8f50aacbe079a026391616cf22453de528f2a873/config.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "print(hf_hub_download(\"lerobot/pi0\", \"config.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:48:00.765] [svulkan2] [error] GLFW error: X11: The DISPLAY environment variable is missing\n",
      "[2025-04-29 04:48:00.765] [svulkan2] [warning] Continue without GLFW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset info {'scene_name': 'google_pick_coke_can_1_v4', 'scene_offset': None, 'scene_pose': None, 'scene_table_height': 0.87, 'urdf_version': 'recolor_tabletop_visual_matching_1', 'rgb_overlay_path': '/data/jul108/SimplerEnv/ManiSkill2_real2sim/data/real_inpainting/google_coke_can_real_eval_1.png', 'rgb_overlay_cameras': ['overhead_camera'], 'rgb_overlay_mode': 'background', 'disable_bad_material': False, 'model_id': 'opened_coke_can', 'model_scale': 1.0, 'distractor_model_ids': None, 'distractor_model_scales': None, 'obj_init_pose_wrt_robot_base': Pose([0.587925, -0.0238302, 0.840576], [0.707052, -0.0081018, -0.01162, -0.70702]), 'orientation': 'laid_vertically'}\n",
      "Instruction pick coke can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import matplotlib.pyplot as plt\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "\n",
    "\n",
    "env = simpler_env.make('google_robot_pick_coke_can')\n",
    "obs, reset_info = env.reset()\n",
    "instruction = env.get_language_instruction()\n",
    "print(\"Reset info\", reset_info)\n",
    "print(\"Instruction\", instruction)\n",
    "\n",
    "image = get_image_from_maniskill2_obs_dict(env, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 04:56:28.364] [svulkan2] [warning] A second renderer will share the same internal context with the first one. Arguments passed to constructor will be ignored.\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_language_instruction to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_language_instruction` for environment variables or `env.get_wrapper_attr('get_language_instruction')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.robot_uid to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.robot_uid` for environment variables or `env.get_wrapper_attr('robot_uid')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: pick coke can\n"
     ]
    }
   ],
   "source": [
    "import simpler_env\n",
    "from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict\n",
    "import torch, numpy as np\n",
    "from PIL import Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# ---- 1. 加载 π0（自定义 config，避免 DecodingError） ----\n",
    "from lerobot.common.policies.pi0.configuration_pi0 import PI0Config\n",
    "from lerobot.common.policies.pi0.modeling_pi0 import PI0Policy\n",
    "from lerobot.configs.types import FeatureType, NormalizationMode, PolicyFeature\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "INPUT = {\n",
    "    \"observation.image.top\": PolicyFeature(type=FeatureType.VISUAL, shape=(3, 224, 224)),\n",
    "    \"observation.state\":     PolicyFeature(type=FeatureType.STATE,  shape=(7,)),\n",
    "}\n",
    "OUTPUT = {\"action\": PolicyFeature(type=FeatureType.ACTION, shape=(7,))}\n",
    "\n",
    "cfg = PI0Config(\n",
    "    input_features=INPUT,\n",
    "    output_features=OUTPUT,\n",
    "    normalization_mapping={\"VISUAL\": NormalizationMode.IDENTITY,\n",
    "                           \"STATE\":  NormalizationMode.IDENTITY,\n",
    "                           \"ACTION\": NormalizationMode.IDENTITY},\n",
    "    device=device,\n",
    ")\n",
    "dummy_stats = {k: {\"mean\": torch.zeros(v.shape), \"std\": torch.ones(v.shape)} for k, v in INPUT.items()}\n",
    "dummy_stats[\"action\"] = {\"mean\": torch.zeros(7), \"std\": torch.ones(7)}\n",
    "\n",
    "policy = PI0Policy.from_pretrained(\n",
    "    \"lerobot/pi0\",          # 会自动下载权重到 ~/.cache/huggingface/hub\n",
    "    config=cfg,\n",
    "    dataset_stats=dummy_stats,\n",
    "    strict=False,           # 忽略缺失 buffer\n",
    ").eval()\n",
    "\n",
    "# ---- 2. 创建 SIMPLER 环境 ----\n",
    "env = simpler_env.make(\"google_robot_pick_coke_can\")\n",
    "obs, reset_info = env.reset()\n",
    "inst = env.get_language_instruction()\n",
    "print(\"Instruction:\", inst)\n",
    "\n",
    "# ---- 3. 主循环 ----\n",
    "done = truncated = False\n",
    "while not (done or truncated):\n",
    "    # 3.1 取图像并缩放到 (3,224,224)\n",
    "    img_np = get_image_from_maniskill2_obs_dict(env, obs)     # (H,W,3) RGB\n",
    "    img_pil = Image.fromarray(img_np).resize((224, 224))\n",
    "    img = torch.as_tensor(np.array(img_pil)).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    # 3.2 取 7 维关节角（谷歌臂为 7 DoF；若找不到就用零向量）\n",
    "    state = torch.as_tensor(obs.get(\"agent\", {}).get(\"qpos\", np.zeros(7)))[:7].float()\n",
    "\n",
    "    # 3.3 封装 batch 并推断\n",
    "    batch = {\n",
    "        \"observation.image.top\": img.unsqueeze(0).to(device),\n",
    "        \"observation.state\":     state.unsqueeze(0).to(device),\n",
    "        \"task\": [inst],          # π0 需要文本指令\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        act = policy.select_action(batch).cpu().numpy()       # (7,)\n",
    "\n",
    "    break\n",
    "#     obs, reward, done, truncated, info = env.step(act)\n",
    "#     new_inst = env.get_language_instruction()\n",
    "#     if new_inst != inst:\n",
    "#         inst = new_inst\n",
    "#         print(\"New instruction →\", inst)\n",
    "\n",
    "# print(\"Episode stats:\", info.get(\"episode_stats\", {}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07079999,  0.26439357,  0.2961598 ,  1.3624268 , -0.17620404,\n",
       "         0.07293497, -0.05996808]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory /mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot is neither a `Dataset` directory nor a `DatasetDict` directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/jul108/SimplerEnv/test.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Approach 1: If the dataset was downloaded by Hugging Face and cached\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# local_path = \"/mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# ds = load_dataset(\"IPEC-COMMUNITY/bridge_orig_lerobot\", split=\"train\", data_dir=local_path, local_files_only=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Approach 2: If the dataset was saved using save_to_disk\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ds \u001b[39m=\u001b[39m load_from_disk(local_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Continue with your existing code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Byixing/data/jul108/SimplerEnv/test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(ds\u001b[39m.\u001b[39mcolumn_names)\n",
      "File \u001b[0;32m/data/jul108/miniconda3_new/envs/simpler_env/lib/python3.10/site-packages/datasets/load.py:2148\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[39mreturn\u001b[39;00m DatasetDict\u001b[39m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory, storage_options\u001b[39m=\u001b[39mstorage_options)\n\u001b[1;32m   2147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   2149\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDirectory \u001b[39m\u001b[39m{\u001b[39;00mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2150\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory /mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot is neither a `Dataset` directory nor a `DatasetDict` directory."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np\n",
    "\n",
    "# Approach 1: If the dataset was downloaded by Hugging Face and cached\n",
    "# local_path = \"/mnt/pentagon/rutu/.cache/lerobot/IPEC-COMMUNITY/bridge_orig_lerobot\"\n",
    "# ds = load_dataset(\"IPEC-COMMUNITY/bridge_orig_lerobot\", split=\"train\", data_dir=local_path, local_files_only=True)\n",
    "\n",
    "# Approach 2: If the dataset was saved using save_to_disk\n",
    "ds = load_from_disk(local_path)\n",
    "\n",
    "# Continue with your existing code\n",
    "print(ds.column_names)\n",
    "\n",
    "obs_array = np.stack(ds[\"obs\"])\n",
    "action_array = np.stack(ds[\"action\"])\n",
    "\n",
    "obs_mean = obs_array.mean(axis=0)\n",
    "obs_std = obs_array.std(axis=0)\n",
    "action_mean = action_array.mean(axis=0)\n",
    "action_std = action_array.std(axis=0)\n",
    "\n",
    "dataset_stats = {\n",
    "    \"obs_mean\": obs_mean.tolist(),\n",
    "    \"obs_std\": obs_std.tolist(),\n",
    "    \"action_mean\": action_mean.tolist(),\n",
    "    \"action_std\": action_std.tolist()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"config_with_stats.json\", \"w\") as f:\n",
    "    json.dump({\"dataset_stats\": dataset_stats}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
